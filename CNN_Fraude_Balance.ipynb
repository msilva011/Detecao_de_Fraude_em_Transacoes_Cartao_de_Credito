{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, Reshape\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de transações fraudulentas: 284315\n"
     ]
    }
   ],
   "source": [
    "# Carregando o dataset\n",
    "data = pd.read_csv('creditcard_2023.csv')\n",
    "\n",
    "# Contando a quantidade de transações fraudulentas\n",
    "num_frauds = data['Class'].sum()\n",
    "print(f\"Número de transações fraudulentas: {num_frauds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando features e target\n",
    "X = data.drop(['Class', 'id'], axis=1)\n",
    "y = data['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o conjunto de dados em treino, validação e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar as classes majoritária e minoritária\n",
    "major_class = data[data['Class'] == 0]\n",
    "minor_class = data[data['Class'] == 1]\n",
    "\n",
    "# Fazer oversampling da classe minoritária para igualar à classe majoritária\n",
    "minor_oversampled = resample(minor_class, replace=True, n_samples=len(major_class), random_state=42)\n",
    "\n",
    "# Combinar as classes reamostradas com a classe majoritária\n",
    "balanced_data = pd.concat([major_class, minor_oversampled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando novamente os dados balanceados em features e target\n",
    "X_balanced = balanced_data.drop(['Class', 'id'], axis=1)\n",
    "y_balanced = balanced_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados balanceados em treino e teste\n",
    "X_train_balanced, X_test_balanced, y_train_balanced, y_test_balanced = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dividindo o conjunto de treinamento balanceado em treinamento final e validação\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_balanced, y_train_balanced, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Convolutional Neural Network (CNN)\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def build_cnn_model_with_dropout():\n",
    "    input_layer = Input(shape=(X_train_final.shape[1],))  \n",
    "    x = Reshape((X_train_final.shape[1], 1))(input_layer) \n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.25)(x) \n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)  # Adicionando Dropout antes da camada densa\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando dados balanceados para a CNN com novo input_shape\n",
    "X_train_final_cnn = X_train_final.values.reshape((X_train_final.shape[0], X_train_final.shape[1], 1))\n",
    "X_val_cnn = X_val.values.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test_balanced_cnn = X_test_balanced.values.reshape((X_test_balanced.shape[0], X_test_balanced.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5687/5687 [==============================] - 44s 8ms/step - loss: 0.1208 - accuracy: 0.9560 - val_loss: 0.0827 - val_accuracy: 0.9682\n",
      "Epoch 2/10\n",
      "5687/5687 [==============================] - 43s 7ms/step - loss: 0.0983 - accuracy: 0.9645 - val_loss: 0.0784 - val_accuracy: 0.9696\n",
      "Epoch 3/10\n",
      "5687/5687 [==============================] - 30s 5ms/step - loss: 0.0964 - accuracy: 0.9652 - val_loss: 0.0765 - val_accuracy: 0.9726\n",
      "Epoch 4/10\n",
      "5687/5687 [==============================] - 26s 5ms/step - loss: 0.0957 - accuracy: 0.9658 - val_loss: 0.0743 - val_accuracy: 0.9723\n",
      "Epoch 5/10\n",
      "5687/5687 [==============================] - 40s 7ms/step - loss: 0.0938 - accuracy: 0.9666 - val_loss: 0.0737 - val_accuracy: 0.9717\n",
      "Epoch 6/10\n",
      "5687/5687 [==============================] - 40s 7ms/step - loss: 0.0933 - accuracy: 0.9664 - val_loss: 0.0728 - val_accuracy: 0.9728\n",
      "Epoch 7/10\n",
      "5687/5687 [==============================] - 33s 6ms/step - loss: 0.0920 - accuracy: 0.9671 - val_loss: 0.0745 - val_accuracy: 0.9703\n",
      "Epoch 8/10\n",
      "5687/5687 [==============================] - 27s 5ms/step - loss: 0.0931 - accuracy: 0.9670 - val_loss: 0.0726 - val_accuracy: 0.9723\n",
      "Epoch 9/10\n",
      "5687/5687 [==============================] - 34s 6ms/step - loss: 0.0926 - accuracy: 0.9670 - val_loss: 0.0720 - val_accuracy: 0.9728\n",
      "Epoch 10/10\n",
      "5687/5687 [==============================] - 43s 7ms/step - loss: 0.0921 - accuracy: 0.9672 - val_loss: 0.0724 - val_accuracy: 0.9731\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo com o conjunto final de treinamento e validação\n",
    "cnn_model = build_cnn_model_with_dropout()\n",
    "history = cnn_model.fit(X_train_final_cnn, y_train_final, epochs=100, batch_size=64, validation_data=(X_val_cnn, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrsilva\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "cnn_model.save('CNN_fraude_cartao.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2844/2844 [==============================] - 5s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Realizando previsões com a CNN nos dados de validação\n",
    "cnn_predictions_val = cnn_model.predict(X_val_cnn)\n",
    "cnn_predictions_val = np.round(cnn_predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o desempenho da CNN nos dados de validação\n",
    "cnn_accuracy_val = accuracy_score(y_val, cnn_predictions_val)\n",
    "cnn_precision_val = precision_score(y_val, cnn_predictions_val)\n",
    "cnn_confusion_val = confusion_matrix(y_val, cnn_predictions_val)\n",
    "cnn_recall_val = recall_score(y_val, cnn_predictions_val)\n",
    "cnn_f1_val = f1_score(y_val, cnn_predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------CNN Metrics on Validation Data:---------\n",
      "\n",
      "Accuracy: 0.9730822919071015\n",
      "\n",
      "Confusion Matrix:\n",
      "[[45080   587]\n",
      " [ 2014 43300]]\n",
      "Precision: 0.9866046089226927\n",
      "\n",
      "Recall: 0.9589751511674096\n",
      "\n",
      "F1 Score: 0.972593695095066\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n------CNN Metrics on Validation Data:---------\\n\")\n",
    "print(f\"Accuracy: {cnn_accuracy_val}\\n\")\n",
    "print(f\"Confusion Matrix:\\n{cnn_confusion_val}\")\n",
    "print(f\"Precision: {cnn_precision_val}\\n\")\n",
    "print(f\"Recall: {cnn_recall_val}\\n\")\n",
    "print(f\"F1 Score: {cnn_f1_val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
